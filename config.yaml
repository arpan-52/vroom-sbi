# VROOM-SBI Configuration File

# Frequency file path
freq_file: "freq.txt"

# Faraday depth range (rad/m^2)
phi:
  min: -1000. 0
  max: 1000.0
  n_samples: 200

# Prior ranges for parameters
priors:
  rm:
    min: -500.0
    max: 500.0
  amp:
    min: 0.01
    max: 1.0

# Noise configuration
# Base noise level - actual noise σ = base_level / weight
# During training, base_level is randomly varied for robustness
noise:
  base_level: 0.01           # Default/reference noise level
  augmentation:
    enable: true             # Enable random noise level variation
    min_factor: 0.5          # Minimum: 0.5 × base_level
    max_factor: 2.0          # Maximum: 2.0 × base_level

# Training settings
training:
  n_simulations: 10000        # Base simulations (for N=1)
  simulation_scaling: true    # Scale up for complex models (N=2,3,4,5)
  batch_size: 50
  n_rounds: 1
  device: "cuda"  # or "cpu"
  validation_fraction: 0.1
  save_dir: "models"
  
# Model selection
model_selection:
  max_components: 2  # Two-layer system: 1-comp and 2-comp only
  use_log_evidence: true
  use_decision_layer: true  # Enable decision layer for model selection
  decision_layer_only: true # If true, skip worker model training (posteriors must exist)
# Weight augmentation settings
weight_augmentation:
  enable: true
  scattered_prob: 0.3      # Probability of scattered missing channels
  gap_prob: 0.3            # Probability of contiguous gaps
  large_block_prob: 0.1    # Probability of large RFI blocks
  noise_variation: true    # Add variation to weights

# Quality Prediction Decision Layer
# NOTE: This is expensive during training because we fit both SBI models
# to each simulated spectrum to compute true AIC/BIC/log_evidence
decision_layer:
  n_training_samples: 10000  # Reduced (each sample requires fitting 2 SBI models!)
  n_posterior_samples: 1000 # Samples from posterior for computing log_evidence/AIC/BIC
  n_epochs: 50              # More epochs for regression task
  batch_size: 32            # Smaller batch size
  learning_rate: 0.0005     # Lower learning rate for stability
  validation_fraction: 0.2
  hidden_dims: [256, 128, 64]  # Network architecture
  selection_strategy: 'ensemble'  # Options: 'log_evidence', 'aic', 'bic', 'ensemble'

# SBI Architecture (Neural Posterior Estimation)
sbi:
  model: 'nsf'               # Neural Spline Flow (better than MAF)
  hidden_features: 128       # Size of hidden layers in flow
  num_transforms: 10         # Number of flow transforms (more = better expressivity)
  num_bins: 16               # Spline resolution
  embedding_dim: 64          # Output dimension of spectral embedding