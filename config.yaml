# VROOM-SBI Configuration File

# Frequency file path
freq_file: "freq.txt"

# Faraday depth range (rad/m^2)
phi:
  min: -1000.0
  max: 1000.0
  n_samples: 200

# Prior ranges for parameters
priors:
  rm:
    min: 0.0
    max: 500.0
  amp:
    min: 0.01
    max: 1.0

# Noise configuration
# Base noise level - actual noise σ = base_level / weight
# During training, base_level is randomly varied for robustness
noise:
  base_level: 0.01           # Default/reference noise level
  augmentation:
    enable: true             # Enable random noise level variation
    min_factor: 0.5          # Minimum: 0.5 × base_level
    max_factor: 2.0          # Maximum: 2.0 × base_level

# Training settings
training:
  n_simulations: 20000        # Base simulations (for N=1)
  simulation_scaling: true    # Scale up for complex models (N=2 gets 2x)
  batch_size: 50
  n_rounds: 1
  device: "cuda"  # or "cpu"
  validation_fraction: 0.1
  save_dir: "models"
  
# Model selection
model_selection:
  max_components: 5           # Support 1-5 components (full scale!)
  use_classifier: true        # Use the new direct classifier
  classifier_only: false      # If true, skip worker model training (simulations must exist)

# Physical model types
# CROSS-MODEL TRAINING: Train all model types together!
# Classifier will learn to distinguish between ALL combinations
physics:
  # Train ALL these model types (4 models × 5 components = 20 classes!)
  model_types:
    - "faraday_thin"
    - "burn_slab"
    - "external_dispersion"
    - "internal_dispersion"

  # For single-model training, use model_type (string) instead of model_types (list)
  # model_type: "faraday_thin"  # Uncomment to train only one model

  # Model-specific parameters
  burn_slab:
    depolarization_sigma: 0.1  # Depolarization parameter

  external_dispersion:
    max_sigma_phi: 200.0  # Maximum RM dispersion

  internal_dispersion:
    max_sigma_phi: 200.0  # Maximum RM dispersion

# Weight augmentation settings
# These are applied during simulation for both posterior and classifier training
weight_augmentation:
  enable: true
  scattered_prob: 0.3         # Probability of scattered missing channels
  gap_prob: 0.3               # Probability of contiguous gaps  
  large_block_prob: 0.1       # Probability of large RFI blocks
  noise_variation: true       # Add variation to weights

# Model Selection Classifier (1D CNN)
# A convolutional classifier that learns to predict N from spectra
# Uses the same simulations as posterior training (no extra cost!)
classifier:
  # CNN Architecture
  conv_channels: [32, 64, 128]  # Channels in each conv layer
  kernel_sizes: [7, 5, 3]       # Kernel size for each conv layer
  dropout: 0.1                  # Dropout for regularization
  
  # Training
  n_epochs: 50                  # Training epochs
  batch_size: 128               # Batch size (can be large, fast training)
  learning_rate: 0.001          # Adam learning rate
  validation_fraction: 0.2      # Fraction for validation
  use_posterior_simulations: true  # Reuse simulations from posterior training

# SBI Architecture (Neural Posterior Estimation)
sbi:
  model: 'nsf'               # Neural Spline Flow (better than MAF)
  hidden_features: 128       # Size of hidden layers in flow
  num_transforms: 10         # Number of flow transforms (more = better expressivity)
  num_bins: 16               # Spline resolution
  embedding_dim: 64          # Output dimension of spectral embedding